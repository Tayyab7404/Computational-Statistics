# -*- coding: utf-8 -*-
"""CS LAB CYCLE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gbspT8KXdemw1oeRYR-Cp_XwIyvW-uuv

## Program 1:
#### Write a python program to find the best fit straight line of the form y = a+bx and draw the scatter plot.
"""

# Linear Regression:

import matplotlib.pyplot as plt
import numpy as np

def mymean(data):
    Sum = 0
    n = len(data)
    for i in data:
        Sum += i
    return Sum/n

def drawPlotLine(x,y,Y_cal):
    Y_color = 'green'
    Y_cal_color = 'red'
    plt.plot(x,y,color=Y_color,marker='o',markerfacecolor='w')
    plt.plot(x,Y_cal,color=Y_cal_color,marker='o',markerfacecolor='w')
    plt.xlabel('x - axis')
    plt.ylabel('y - axis')
    plt.title("Best Fit Line")
    plt.show()
    print("X-Y Graph: Green")
    print("X-Ycal Graph: Red")

def LinearRegression(x,y):
    n = len(x)
    m = len(y)

    if n != m:
        print("Invalid Data!")
        return

    SumX = sum(x)
    SumY = sum(y)

    slope = (n*sum(x*y) - SumX*SumY) / (n*sum(x**2) - SumX**2)
    constant = (SumY - slope*SumX) / n

    Y_cal = slope*x + constant

    meanY = mymean(y)

    SST = sum((y-meanY)**2)
    SSE = sum((y-Y_cal)**2)
    SSR = sum((Y_cal-meanY)**2)

    Rsq = SSR/SST
    # Rsq = 1 - SSE/SST

    print("Y Calculated values: ",Y_cal)
    print("The Linear Regression Line for the given data:")
    print("Y = ({:.4f}) + ({:.4f})X".format(constant,slope))
    print("Sum of Squares due to Total (SST): {:.4f}".format(SST))
    print("Sum of Squares due to Regression (SSR): {:.4f}".format(SSR))
    print("Sum of Squares due to Error (SSE): {:.4f}".format(SSE))
    print("R Square value: {:.4f}".format(Rsq))

    drawPlotLine(x,y,Y_cal)

    if Rsq > 0.9:
        print("The Regression Line Y = ({:.4f}) + ({:.4f})X is the best fit for given data".format(constant,slope))
    else:
        print("The Regression Line Y = ({:.4f}) + ({:.4f})X is not the best fit for given data".format(constant,slope))

x = np.array([float(i) for i in input("Enter x values: ").strip().split()])
y = np.array([float(i) for i in input("Enter y values: ").strip().split()])

LinearRegression(x,y)

"""## Program 2:
#### Write a python program to fit a second degree parabola of the form y = a+bx+cx2 and draw the scatter plot.
"""

# Parabola Regression:

import matplotlib.pyplot as plt
import numpy as np

def mymean(data):
    Sum = 0
    n = len(data)
    for i in data:
        Sum += i
    return Sum/n

def drawPlotParabola(x,y,Y_cal):
    Y_color = 'green'
    Y_cal_color = 'red'
    plt.plot(x,y,color=Y_color,marker='o',markerfacecolor='w')
    plt.plot(x,Y_cal,color=Y_cal_color,marker='o',markerfacecolor='w')
    plt.xlabel('x - axis')
    plt.ylabel('y - axis')
    plt.title("Best Fit Curve")
    plt.show()
    print("X-Y Graph: Green")
    print("X-Ycal Graph: Red")

def DET(matrix):
    Sum = 0

    Sum += matrix[0][0] * (matrix[1][1]*matrix[2][2] - matrix[2][1]*matrix[1][2])
    Sum -= matrix[0][1] * (matrix[1][0]*matrix[2][2] - matrix[2][0]*matrix[1][2])
    Sum += matrix[0][2] * (matrix[1][0]*matrix[2][1] - matrix[2][0]*matrix[1][1])

    return Sum

def ParabolaRegression(x,y):
    n = len(x)
    m = len(y)

    if n != m:
        print("Invalid Data!")
        return

    x2 = x*x
    x3 = x2*x
    x4 = x3*x
    xy = x*y
    x2y = x2*y

    Sumx = sum(x)
    Sumx2 = sum(x2)
    Sumx3 = sum(x3)
    Sumx4 = sum(x4)
    Sumy = sum(y)
    Sumxy = sum(xy)
    Sumx2y = sum(x2y)

    delta  = DET([[n, Sumx, Sumx2],
                  [Sumx, Sumx2, Sumx3],
                  [Sumx2, Sumx3, Sumx4]])

    delta1 = DET([[Sumy, Sumx, Sumx2],
                  [Sumxy, Sumx2, Sumx3],
                  [Sumx2y, Sumx3, Sumx4]])

    delta2 = DET([[n, Sumy, Sumx2],
                  [Sumx, Sumxy, Sumx3],
                  [Sumx2, Sumx2y, Sumx4]])

    delta3 = DET([[n, Sumx, Sumy],
                  [Sumx, Sumx2, Sumxy],
                  [Sumx2, Sumx3, Sumx2y]])

    a = delta1 / delta
    b = delta2 / delta
    c = delta3 / delta

    Y_cal = a + b*x + c*x2

    mean_Y = mymean(y)

    SST = sum((y-mean_Y)**2)
    SSE = sum((y-Y_cal)**2)
    SSR = sum((Y_cal-mean_Y)**2)

    Rsq = SSR/SST
    # Rsq = 1 - SSE/SST

    print("Y Calculated values: ",Y_cal)
    print("The Parabola Regression Curve for the given data: ")
    print("Y = ({:.4f}) + ({:.4f})X + ({:.4f})X2".format(a,b,c))
    print("Sum of Squares due to Total (SST): {:.4f}".format(SST))
    print("Sum of Squares due to Regression (SSR): {:.4f}".format(SSR))
    print("Sum of Squares due to Error (SSE): {:.4f}".format(SSE))
    print("R Square value: {:.4f}".format(Rsq))

    drawPlotParabola(x,y,Y_cal)

    if Rsq > 0.9:
        print("The Regression Curve Y = ({:.4f}) + ({:.4f})X + ({:.4f})X2 is the best fit for given data.".format(a,b,c))
    else:
        print("The Regression Curve Y = ({:.4f}) + ({:.4f})X + ({:.4f})X2 is not the best fit for given data.".format(a,b,c))

x = np.array([float(i) for i in input("Enter x values: ").strip().split()])
y = np.array([float(i) for i in input("Enter y values: ").strip().split()])

ParabolaRegression(x, y)

"""## Program 3:
#### Write a python program to find Karl Pearson’s correlation coefficient between X and Y variables.
"""

# Karl Pearson's Correlation Coefficient:

import numpy as np
from math import sqrt

def mymean(data):
    Sum = 0
    n = len(data)
    for i in data:
        Sum += i

    return Sum/n

def CovXY(x,y):
    n = len(x)
    meanX = mymean(x)
    meanY = mymean(y)
    SumXY = sum(x*y)
    CovXY = (SumXY/n) - (meanX*meanY)

    return CovXY

def SD(x):
    n = len(x)
    meanx = mymean(x)
    Sumx2 = sum(x**2)
    var = (Sumx2/n) - (meanx**2)

    return sqrt(var)

def KPCC(x,y):
    if len(x) != len(y):
        print("Invalid Data!")
        return

    Covxy = CovXY(x,y)
    SDx = SD(x)
    SDy = SD(y)

    KPCC = Covxy / (SDx*SDy)

    print("Co-variance of X and Y = {:.4f}".format(Covxy))
    print("Standard Deviation of X = {:.4f}".format(SDx))
    print("Standard Deviation of Y = {:.4f}".format(SDy))

    if KPCC > -1 and KPCC < 1:
        print("The Karl Pearson's Correlation Coefficient of the given data is: {:.4f}".format(KPCC))
    else:
        print("Invalid Data!")

x = np.array([float(i) for i in input("Enter x values: ").strip().split()])
y = np.array([float(i) for i in input("Enter y values: ").strip().split()])

KPCC(x,y)

"""## Program 4:
#### Write a python program to find the Spearman’s correlation coefficient between X and Y variables.
"""

# Spearman's Rank Correlation Coefficient:

import pandas as pd
import numpy as np

def Rankify(data):
    N = len(data)
    Ranks = [None for i in range(N)]

    for i in range(N):
        BigNums = 0
        SameNums = 0

        for j in range(N):
            if (data[j] > data[i]):
                BigNums += 1
            if (data[j] == data[i]):
                SameNums += 1

        # Use Fractional Rank formula
        # fractional_rank = (BigNums+1) + (SameNums-1)/2
        Ranks[i] = (BigNums+1) + (SameNums-1)/2

    return Ranks

def RemDups(data):
    set_data = []

    for i in data:
        if i not in set_data:
            set_data.append(i)

    return set_data

def CF(x,y):
    cf = 0
    x = list(x)
    y = list(y)
    set_x = RemDups(x)
    set_y = RemDups(y)

    for i in set_x:
        count_x = x.count(i)
        if count_x > 1:
            cf += (count_x * (count_x**2 - 1)) / 12

    for i in set_y:
        count_y = y.count(i)
        if count_y > 1:
            cf += (count_y * (count_y**2 - 1)) / 12

    return cf

def SRCC(x,y):
    n = len(x)
    m = len(y)

    if n != m:
        print("Invalid Data!")
        return

    RankX = np.array(Rankify(x))
    RankY = np.array(Rankify(y))

    # Difference of Ranks:
    Di = RankX - RankY
    DiSq = Di**2

    SumDiSq = sum(DiSq)

    # Correction Factor:
    cf = CF(x,y)
    SumDiSq += cf

    SRCC = 1 - ((6 * SumDiSq) / (n * (n**2 - 1)))

    SRCC_Table = {
        "X values": x,
        "Y values": y,
        "Ranks of X": RankX,
        "Ranks of Y": RankY,
        "Di values": Di,
        "Di sq. values": DiSq}

    print(pd.DataFrame(SRCC_Table))

    print("Correction Factor: ",cf)
    print("Sum of Di sq: ",SumDiSq)
    print("The Spearman's Ranked Correlation Coefficient of the given data: {:.4f}".format(SRCC))

x = np.array([float(i) for i in input("Enter x values: ").strip().split()])
y = np.array([float(i) for i in input("Enter y values: ").strip().split()])

SRCC(x,y)

"""## Program 5:
#### Write a python program to classify the data based on one way ANOVA.
"""

# ANOVA One Way Classification:

import pandas as pd
import numpy as np
import scipy.stats as ss

k = int(input("Enter the number of Treatments: "))
Treatment = input("Enter name of the Treatments: ")

Data = []
for i in range(k):
    a = np.array([float(j) for j in input(f"Enter {Treatment} {i+1} values: ").strip().split()])
    Data.append(a)

Data = np.array(Data)

alpha = float(input("Enter Level of Significance: "))

print(f"\nNull Hypothesis (H0): There is Homogenity among the {Treatment}s")
print(f"Alternate Hypothesis (H1): There is Heterogenity among the {Treatment}s\n")

# Total No. of values (N):
# Sum of Treatments (Ti):
# Row sum of squares (RSS):
N = Ti = Ti2 = RSS = 0
for i in Data:
    Ti += sum(i)
    Ti2 += sum(i)**2 / len(i)
    RSS += sum(i**2)
    N += len(i)

# Correction Factor (CF):
CF = Ti**2 / N

# Sum of Squares due to Total (SST):
SST = RSS - CF
# Sum of Squares due to Treatments (SSTr):
SSTr = Ti2 - CF
# Sum of Squares due to Error (SSE):
SSE = SST - SSTr

# Mean Sum of Squares due to Treatments (MeanSSTr):
MeanSSTr = SSTr/(k-1)
# Mean Sum of Squares due to Error (MeanSSE):
MeanSSE = SSE/(N-k)

# F calculated value:
Fcal = MeanSSTr / MeanSSE

# F table value:
FTable = ss.f.ppf(1-alpha, k-1, N-k)

# Degrees of Freedom:
DOF = f"~ F({k-1},{N-k})"

if(Fcal < 1):
    Fcal = 1 / Fcal
    FTable = ss.f.ppf(1-alpha, N-k, k-1)
    DOF = f"~ F({N-k},{k-1})"

print("Sum of Squares due to Total (SST): {:.4f}".format(SST))
print("Sum of Squares due to Treatments (SSTr): {:.4f}".format(SSTr))
print("Sum of Squares due to Error (SSE): {:.4f}\n".format(SSE))

print("Mean Sum of Squares due to Treatments (Mean SSTr): {:.4f}".format(MeanSSTr))
print("Mean Sum of Squares due to Error (Mean SSE): {:.4f}\n".format(MeanSSE))

ANOVA_One_Way_Classification_Table = {
    "S O V": [Treatment, "Error", "Total"],
    "S O S": ["{:.4f}".format(SSTr), "{:.4f}".format(SSE), "{:.4f}".format(SST)],
    "D O F": [k-1, N-k, N-1],
    "M S O S": ["{:.4f}".format(MeanSSTr), "{:.4f}".format(MeanSSE), " - "],
    "V R": ["F-cal = {:.4f}".format(Fcal), DOF, ""]}

data_frame = pd.DataFrame(ANOVA_One_Way_Classification_Table)

print("ANOVA One Way Classification Table:")
print(data_frame)

print("\nF-Calculated value: {:.4f}".format(Fcal))
print("F-Table value: {:.4f}\n".format(FTable))

if Fcal < FTable :
    print(f"We Accept H0\nThere is Homogeneity among the {Treatment}s")
else:
    print(f"We Reject H0\nThere is Heterogeneity among the {Treatment}s")

"""## Program 6:
#### Write a python program to classify the data based on two way ANOVA.
"""

# ANOVA Two Way Classification:

import pandas as pd
import numpy as np
import scipy.stats as ss

def mymean(data):
    Sum = 0
    for i in data:
        Sum += i

    return Sum/len(data)

k = int(input("Enter the number of Treatments: "))
h = int(input("Enter the number of Blocks: "))

Treatment = input("Enter name of the Treatments: ")
Block = input("Enter name of the Blocks: ")

Data = []
for i in range(k):
    row = []
    while len(row) != h:
        row = np.array([float(i) for i in input(f"Enter {Treatment} {i+1} values: ").strip().split()])
    Data.append(row)

Data = np.array(Data)

alpha = float(input("Enter Level of Significance: "))

print(f"\nHypothesis Related to {Treatment}s:")
print(f"Null Hypothesis (H0): There is Homogenity among the {Treatment}s")
print(f"Alternate Hypothesis (H1): There is Heterogenity among the {Treatment}s")

print(f"\nHypothesis Related to {Block}s:")
print(f"Null Hypothesis (H0): There is Homogenity among the {Block}s")
print(f"Alternate Hypothesis (H1): There is Heterogenity among the {Block}s\n")

# Total no. of values (N):
N = k * h

# Sum of Treatments (Ti):
Ti = np.array([sum(i) for i in Data])
Ti2 = Ti**2
SumTi2 = sum(Ti2)

# Sum of Blocks (Bj):
Bj = Data[0]
for i in range(1,k):
    Bj = Bj + Data[i]

Bj2 = Bj**2
SumBj2 = sum(Bj2)

# Grand Total (G):
G = sum(Ti)

# Row Sum of Squares (RSS):
RSS = 0
for i in Data:
    for j in i:
        RSS += j**2

# Correction Factor (CF):
CF = G**2 / N

# Sum of Squares due to Total (SST):
SST = RSS - CF
# Sum of Squares due to Treatments (SSTr):
SSTr = SumTi2/h - CF
# Sum of Squares due to Blocks (SSB):
SSB = SumBj2/k - CF
# Sum of Squares due to Error (SSE):
SSE = SST - SSTr - SSB

# Mean Sum of Squares due to Treatments (MeanSSTr):
MeanSSTr = SSTr/(k-1)
# Mean Sum of Squares due to Blocks (MeanSSB):
MeanSSB = SSB/(h-1)
# Mean Sum of Squares due to Error (MeanSSE):
MeanSSE = SSE/((k-1)*(h-1))

# F calculated value of Treatments (F(Tr)):
F_Tr_cal = MeanSSTr / MeanSSE
# F calculated value of Blocks (F(B)):
F_B_cal = MeanSSB / MeanSSE

# F table value of Treatments:
F_Tr_Table = ss.f.ppf(1-alpha, k-1, (k-1)*(h-1))
# F table value of Blocks:
F_B_Table = ss.f.ppf(1-alpha, h-1, (k-1)*(h-1))

# Degrees of Freedom for Treatments:
F_Tr_DOF = f"~ F({k-1},{(k-1)*(h-1)})"
# Degrees of Freedom for Blocks:
F_B_DOF = f"~ F({h-1},{(k-1)*(h-1)})"

if F_Tr_cal < 1:
    F_Tr_cal = 1 / F_Tr_cal
    F_Tr_Table = ss.f.ppf(1-alpha,(k-1)*(h-1), k-1)
    F_Tr_DOF = f"~ F({(k-1)*(h-1)},{k-1})"

if F_B_cal < 1:
    F_B_cal = 1 / F_B_cal
    F_B_Table = ss.f.ppf(1-alpha,(k-1)*(h-1), h-1)
    F_B_DOF = f"~ F({(k-1)*(h-1)},{h-1})"

print("Sum of Squares due to Total (SST): {:.4f}".format(SST))
print("Sum of Squares due to Treatments (SSTr): {:.4f}".format(SSTr))
print("Sum of Squares due to Blocks (SSB): {:.4f}".format(SSB))
print("Sum of Squares due to Error (SSE): {:.4f}\n".format(SSE))

print("Mean Sum of Squares due to Treatments (Mean SSTr): {:.4f}".format(MeanSSTr))
print("Mean Sum of Squares due to Blocks (Mean SSB): {:.4f}".format(MeanSSB))
print("Mean Sum of Squares due to Error (Mean SSE): {:.4f}\n".format(MeanSSE))

ANOVA_Two_Way_Classification_Table = {
    "S O V": [Treatment, Block, "Error", "Total"],
    "S O S": ["{:.4f}".format(SSTr), "{:.4f}".format(SSB), "{:.4f}".format(SSE), "{:.4f}".format(SST)],
    "D O F": [k-1, h-1, (k-1)*(h-1), (k*h)-1],
    "M S O S": ["{:.4f}".format(MeanSSTr), "{:.4f}".format(MeanSSB), "{:.4f}".format(MeanSSE), " - "],
    "V R": ["F(Tr)-cal = {:.4f}".format(F_Tr_cal), F_Tr_DOF,
            "F(B)-cal = {:.4f}".format(F_B_cal), F_B_DOF]}

data_frame = pd.DataFrame(ANOVA_Two_Way_Classification_Table)

print("ANOVA Two Way Classification Table:")
print(data_frame)

print(f"\nInference Related to {Treatment}s:")
print("F(Tr) Calculated value: {:.4f}".format(F_Tr_cal))
print("F(Tr) Table value: {:.4f}\n".format(F_Tr_Table))

if F_Tr_cal < F_Tr_Table:
    print(f"We Accept H0(Tr)\nThere is Homogeneity among the {Treatment}s")
else:
    print(f"We Reject H0(Tr)\nThere is Heterogeneity among the {Treatment}s")

print(f"\nInference Related to {Block}s:")
print("F(B) Calculated value: {:.4f}".format(F_B_cal))
print("F(B) Table value: {:.4f}\n".format(F_B_Table))

if F_B_cal < F_B_Table:
    print(f"We Accept H0(B)\nThere is Homogeneity among the {Block}s\n")
else:
    print(f"We Reject H0(B)\nThere is Heterogeneity among the {Block}s\n")

"""## Program 7:
#### Write a python program to fit a multiple regression model for any given data.
"""

# Multiple Linear Regression Model:

import numpy as np
import scipy.stats as ss
from math import sqrt

def mymean(data):
    return sum(data)/len(data)

def GoodnessOfFit(y , Yfitted, alpha, Beta):
    print("\nTo Test Goodness of Fit using Determination of Coefficients (R2):")

    ybar = mymean(y)
    Residual = y - Yfitted
    y_ybar = y-ybar

    SSE = sum(Residual**2)
    SST = sum(y_ybar**2)
    SSR = SST - SSE

    Rsq = SSR/SST

    print(f"Coefficient of Determination (R2): {Rsq}")

    if Rsq < 0.9:
        print("The Multiple Regression Model is Not a Good Fit for the given data.")
    else:
        print("The Multiple Regression Model is a Good Fit for the given data.")

    print("\nTo Test Goodness of Fit using ANOVA:")
    n = len(y)
    p = len(Beta)

    MeanSSR = SSR/(p-1)
    MeanSSE = SSE/(n-p)

    Fcal = MeanSSR/MeanSSE
    F_table = ss.f.ppf(1-alpha, p-1, n-p)

    if Fcal < 1:
        Fcal = 1 / Fcal
        F_table = ss.f.ppf(1-alpha, n-p, p-1)

    if Fcal < F_table:
        print(f"Fcal < F-Table ({round(Fcal,4)} < {round(F_table,4)})")
        print("The Multiple Regression Model is Not a Good Fit for the given data.")
    else:
        print(f"Fcal > F-Table ({round(Fcal,4)} < {round(F_table,4)})")
        print("The Multiple Regression Model is a Good Fit for the given data.")

    return SSE

def ParameterTesting(XTX_inverse, alpha, Beta, SSE, DOF):
    print("\nTest for individual parameters:")

    T_table = ss.t.ppf(q = 1 - alpha/2, df = DOF)
    Tcal = []

    for i in range(len(Beta)):
        Tcal.append(Beta[i] / sqrt(SSE/DOF * XTX_inverse[i][i]))

        if Tcal[i] < T_table:
            print(f"Beta {i} is Not contributing to the model.")
        else:
            print(f"Beta {i} is contributing to the model.")

def mat_multiply(mat1, mat2):
    if mat1.shape[1] != mat2.shape[0]:
        print("Cannot multiply the matrices!!")
        return

    mat3 = np.zeros([mat1.shape[0],mat2.shape[1]], dtype=float)

    for i in range(len(mat1)):
        for j in range(len(mat2[0])):
            for k in range(len(mat2)):
                mat3[i][j] += mat1[i][k] * mat2[k][j]

    return mat3

def mat_transpose(mat):
    result = np.zeros((mat.shape[1], mat.shape[0]), dtype=float)

    for i in range(mat.shape[0]):
       for j in range(mat.shape[1]):
           result[j, i] = mat[i, j]

    return result

X_dim = int(input("Enter number of X variables: "))

Y = np.array([[float(j)] for j in input(f"Enter Y values: ").strip().split()])

X = [np.array([1 for i in range(len(Y))])]
for i in range(1, X_dim):
    X_row =  np.array([float(j) for j in input(f"Enter X{i} values: ").strip().split()])
    X.append(X_row)

X = np.array(X)

alpha = float(input("Enter Level of Significance: "))

XTX = mat_multiply(X,mat_transpose(X))

XTX_inv = np.linalg.inv(XTX)

XTY = mat_multiply(X,Y)

result = mat_multiply(XTX_inv,XTY)

Beta = []
for i in result:
  Beta.append(i[0])

Beta = np.array(Beta)

Yfitted = 0
for i in range(len(X)):
    Yfitted += Beta[i]*X[i]

print("\nThe Multiple Linear Regression Model for the given data:")
output = f"Y = ({Beta[0]})"
for i in range(1, len(X)):
    output += f" + ({round(Beta[i],4)})X{i}"
print(output)

y = np.array([i[0] for i in Y])
SSE = GoodnessOfFit(y,Yfitted,alpha, Beta)

DOF = len(Y) - len(Beta)

ParameterTesting(XTX_inv, alpha, Beta, SSE, DOF)

"""## Program 8:
#### Write a python program to fit a multivariate regression model for any given data.
"""

# Multi Variate Linear Regresssion Model:

import numpy as np

def mat_multiply(mat1, mat2):
    if mat1.shape[1] != mat2.shape[0]:
        print("Cannot multiply the matrices!!")
        return

    mat3 = np.zeros([mat1.shape[0],mat2.shape[1]], dtype=float)

    for i in range(len(mat1)):
        for j in range(len(mat2[0])):
            for k in range(len(mat2)):
                mat3[i][j] += mat1[i][k] * mat2[k][j]

    return mat3

def mat_transpose(mat):
    result = np.zeros((mat.shape[1], mat.shape[0]), dtype=float)

    for i in range(mat.shape[0]):
       for j in range(mat.shape[1]):
           result[j][i] = mat[i][j]

    return result

Y_dim = int(input("Enter number of Y variables: "))
X_dim = int(input("Enter number of X variables: "))

Y = []
X = []

for i in range(Y_dim):
    Y_row = np.array([float(j) for j in input(f"Enter Y{i} values: ").strip().split()])
    Y.append(Y_row)

X.append(np.array([1 for i in range(len(Y[0]))]))
for i in range(1, X_dim):
    X_row =  np.array([float(j) for j in input(f"Enter X{i} values: ").strip().split()])
    X.append(X_row)

Y = np.array(Y)
X = np.array(X)

XTX = mat_multiply(X, mat_transpose(X))

XTX_inv = np.linalg.inv(XTX)

XTY = mat_multiply(X,mat_transpose(Y))

Beta = mat_transpose(mat_multiply(XTX_inv,XTY))

Yfitted = []
for i in range(len(Y)):
    row = 0
    for j in range(len(X)):
        row += Beta[i][j]*X[j]
    Yfitted.append(row)

Yfitted = np.array(Yfitted)

print("\nThe Multi Variate Linear Regression Models for the given data:")
for i in range(len(Y)):
    output = f"Y{i} = ({round(Beta[i][0],4)})"
    for j in range(1, len(X)):
        output += f" + ({round(Beta[i][j],4)})X{j}"
    print(output)

"""## Program 9:
#### Write a python program to classify the treatments based on MANOVA Test.

## Program 10:
#### Write a python program to classify the given observations using Linear Discriminant Analysis.
"""

import numpy as np
from math import log as ln

def mymean(data):
    Sum = 0
    for i in data:
        Sum += i
    return Sum/len(data)

#a = np.array([float(i) for i in input("Enter a values: ").strip().split()])
#b = np.array([float(i) for i in input("Enter b values: ").strip().split()])
#c = np.array([float(i) for i in input("Enter c values: ").strip().split()])

#a = np.array([2.95,2.53,3.57,3.16,2.58,2.16,3.27])
#b = np.array([6.63,7.79,5.65,5.47,4.46,6.22,3.52])
#c = np.array([1,1,1,1,0,0,0])

a = np.array([4,2,2,3,4,9,6,9,8,10])
b = np.array([2,4,3,6,4,10,8,5,7,8])
c = np.array([1,1,1,1,1,0,0,0,0,0])

X = np.array([a,b])

#Given_data = np.array([float(i) for i in input("Enter the data to test: ").strip().split()])
#Given_data = np.array([2.81, 5.46])
Given_data = np.array([5,6])

m = []
n = []
p = []
q = []
count_1 = 0
count_0 = 0

for i in range(len(c)):
    if c[i] == 1:
        m.append(a[i])
        n.append(b[i])
        count_1 += 1
    elif c[i] == 0:
        p.append(a[i])
        q.append(b[i])
        count_0 += 1

X1 = [m, n]
X2 = [p, q]

Mu = [mymean(a), mymean(b)]
Mu1 = [mymean(m), mymean(n)]
Mu2 = [mymean(p), mymean(q)]

X_Mu = [a-Mu[0], b-Mu[1]]

# Pooled Covariance Matrix:
PCM = [[sum(X_Mu[0]**2)/len(c), sum(X_Mu[0]*X_Mu[1])/len(c)],
       [sum(X_Mu[1]*X_Mu[0])/len(c), sum(X_Mu[1]**2)/len(c)]]

PCM_inv = np.linalg.inv(PCM)

# Fisher's LDA:
F1_Term1 = sum(np.array([sum(Mu1*PCM_inv[0]), sum(Mu1*PCM_inv[1])]) * Given_data)
F1_Term2 = sum(np.array([sum(Mu1*PCM_inv[0]), sum(Mu1*PCM_inv[1])]) * Mu1)
F1_Term3 = ln(count_1/len(c))

F1 = F1_Term1 - 0.5*F1_Term2 + F1_Term3

F2_Term1 = sum(np.array([sum(Mu2*PCM_inv[0]), sum(Mu2*PCM_inv[1])]) * Given_data)
F2_Term2 = sum(np.array([sum(Mu2*PCM_inv[0]), sum(Mu2*PCM_inv[1])]) * Mu2)
F2_Term3 = ln(count_0/len(c))

F2 = F2_Term1 - 0.5*F2_Term2 + F2_Term3

max_val = F1 if F1>F2 else F2

print(Mu)
print(Mu1)
print(Mu2)

print(X_Mu)

print(PCM)
print(PCM_inv)

print(F1)
print(F2)

if max_val == F1:
    print("The Given Data Belongs to First Group.")
else:
    print("The Given Data Belongs to Second Group.")

"""## Program 11:
#### Write a python program to find Principle components for the given variables.

## Program 12:
#### Write a python program to group the given variables using Factor Analysis.
"""

def transpose(mat):
    result = np.zeros((mat.shape[1], mat.shape[0]), dtype=float)

    for i in range(mat.shape[0]):
       for j in range(mat.shape[1]):
           result[j][i] = mat[i][j]

    return result

def matrix_minor(mat,i,j):
    return [row[:j] + row[j+1:] for row in (mat[:i]+mat[i+1:])]

def det(mat):
    if len(mat) == 2:
        return mat[0][0]*mat[1][1]-mat[0][1]*mat[1][0]

    determinant = 0
    for c in range(len(m)):
        determinant += ((-1)**c)*m[0][c]*determinant(matrix_minor(m,0,c))
    return determinant

def inverse_matrix(m):
    determinant = det(m)
    if len(m) == 2:
        return [[m[1][1]/determinant, -1*m[0][1]/determinant],
                [-1*m[1][0]/determinant, m[0][0]/determinant]]

    cfs = []
    for r in range(len(m)):
        cfRow = []
        for c in range(len(m)):
            minor = matrix_minor(m,r,c)
            cfRow.append(((-1)**(r+c)) * determinant(minor))
        cfs.append(cfRow)
    cfs = transpose(cfs)
    for r in range(len(cfs)):
        for c in range(len(cfs)):
            cfs[r][c] /= determinant
    return cfs